{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model for Distracted Driver Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online Notebook: [Distraction Driver Detection](https://www.kaggle.com/code/andreabernini/distracted-driver)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "\n",
    "# Commented because already present on Kaggle\n",
    "# ! pip install torch\n",
    "# ! pip install pytorch-lightning\n",
    "# ! pip install torchmetrics\n",
    "# ! pip install timm\n",
    "# ! pip install albumentations\n",
    "# ! pip install opencv-python\n",
    "# ! pip install matplotlib\n",
    "# ! pip install pandas\n",
    "# ! pip install scikit-learn\n",
    "# ! pip install tqdm\n",
    "# ! pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from enum import Enum\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import accuracy, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticDataset(Enum):\n",
    "    \"\"\"Class for static training configuration constants\"\"\"\n",
    "\n",
    "    ACTIVITY_MAP = {\n",
    "        \"c0\": \"Safe driving\",\n",
    "        \"c1\": \"Texting - right\",\n",
    "        \"c2\": \"Talking on the phone - right\",\n",
    "        \"c3\": \"Texting - left\",\n",
    "        \"c4\": \"Talking on the phone - left\",\n",
    "        \"c5\": \"Operating the radio\",\n",
    "        \"c6\": \"Drinking\",\n",
    "        \"c7\": \"Reaching behind\",\n",
    "        \"c8\": \"Hair and makeup\",\n",
    "        \"c9\": \"Talking to passenger\",\n",
    "    }\n",
    "    DATA_DIR = \"src/data/dataset/state-farm-distracted-driver-detection/\"\n",
    "    CSV_FILE_PATH = osp.join(DATA_DIR, \"driver_imgs_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticLearningParameter(Enum):\n",
    "    MODEL_NAME_0 = \"efficientnet_b0\"\n",
    "    MODEL_NAME_3 = \"efficientnet_b3\"\n",
    "    COLOR_MEAN = (0.485, 0.456, 0.406)\n",
    "    COLOR_STD = (0.229, 0.224, 0.225)\n",
    "    INPUT_SIZE = 256\n",
    "    NUM_CLASSES = 10\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 10\n",
    "    FOLDS = 5\n",
    "    LR = 1e-3\n",
    "    GAMMA = 0.98\n",
    "    DEBUG = True\n",
    "    TRAIN = False\n",
    "    SEED = 42\n",
    "    USE_ALBUMENTATIONS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = True  # Set True if you want to see some logs\n",
    "PLOT = True  # Set True if you want to plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    \"\"\"Fix the seed of the random number generator for reproducibility.\"\"\"\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file\n",
    "print(os.getcwd())\n",
    "fix_seed(StaticLearningParameter.SEED.value)\n",
    "df = pd.read_csv(\"../\" + StaticDataset.CSV_FILE_PATH.value)\n",
    "# Show first 5 lines\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by driver\n",
    "by_drivers = df.groupby(\"subject\")\n",
    "# list of driver names\n",
    "unique_drivers = by_drivers.groups.keys()\n",
    "\n",
    "# Number of drivers in dataset\n",
    "print(\"unique drivers: \", len(unique_drivers))\n",
    "# Average number of images per driver\n",
    "print(\"mean of images: \", round(df.groupby(\"subject\").count()[\"classname\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training data\n",
    "train_file_num = len(glob(osp.join(StaticDataset.DATA_DIR.value, \"imgs/train/*/*.jpg\")))\n",
    "# number of test data\n",
    "test_file_num = len(glob(osp.join(StaticDataset.DATA_DIR.value, \"imgs/test/*.jpg\")))\n",
    "# number of categories\n",
    "category_num = len(df[\"classname\"].unique())\n",
    "print(\"train_file_num: \", train_file_num)\n",
    "print(\"test_file_num: \", test_file_num)\n",
    "print(\"category_num: \", category_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Images per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data per class\n",
    "px.histogram(\n",
    "    df, x=\"classname\", color=\"classname\", title=\"Number of images by categories \"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Images per Driver"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images per driver sorted by number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_id = pd.DataFrame((df[\"subject\"].value_counts()).reset_index())\n",
    "drivers_id.columns = [\"driver_id\", \"Counts\"]\n",
    "px.histogram(\n",
    "    drivers_id,\n",
    "    x=\"driver_id\",\n",
    "    y=\"Counts\",\n",
    "    color=\"driver_id\",\n",
    "    title=\"Number of images by subjects \",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images per driver sorted by driver id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of number of images per driver\n",
    "px.histogram(df, x=\"subject\", color=\"subject\", title=\"Number of images by subjects\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image for each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw data for each class\n",
    "plt.figure(figsize=(12, 20))\n",
    "for i, (key, value) in enumerate(StaticDataset.ACTIVITY_MAP.value.items()):\n",
    "    image_dir = osp.join(\n",
    "        \"../\" + StaticDataset.DATA_DIR.value, \"imgs/train\", key, \"*.jpg\"\n",
    "    )\n",
    "    image_path = glob(image_dir)[0]\n",
    "    image = cv2.imread(image_path)[:, :, (2, 1, 0)]\n",
    "    plt.subplot(5, 2, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add file path column\n",
    "df[\"file_path\"] = df.apply(\n",
    "    lambda x: osp.join(\n",
    "        \"../\" + StaticDataset.DATA_DIR.value, \"imgs/train\", x.classname, x.img\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Add Column by Converting Correct Answer Labels to Numbers\n",
    "df[\"class_num\"] = df[\"classname\"].map(lambda x: int(x[1]))\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        class_num, dataframe with column file_path\n",
    "    phase : 'train' or 'val'\n",
    "        Set learning or training.\n",
    "    transform : object\n",
    "        an instance of the preprocessing class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, phase, transform):\n",
    "        self.df = df\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"returns the number of images\"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get Tensor format data of preprocessed image\"\"\"\n",
    "        image = self.pull_item(index)\n",
    "        return image, self.df.iloc[index][\"class_num\"]\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        \"\"\"Get Tensor format data of image\"\"\"\n",
    "        # 1. Image loading\n",
    "        image_path = self.df.iloc[index][\"file_path\"]\n",
    "        image = cv2.imread(image_path)[:, :, (2, 1, 0)]\n",
    "        # 2. Perform pretreatment\n",
    "        return self.transform(self.phase, image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Image and annotation preprocessing classes.\n",
    "    It behaves differently during training and during validation.\n",
    "    Set the image size to input_size x input_size.\n",
    "    Data augmentation during training.\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    input_size : int\n",
    "        The size of the resized image.\n",
    "    color_mean : (R, G, B)\n",
    "        Average value for each color channel.\n",
    "    color_std : (R, G, B)\n",
    "        Standard deviation for each color channel.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        color_mean,\n",
    "        color_std,\n",
    "        use_albumentations=StaticLearningParameter.USE_ALBUMENTATIONS.value,\n",
    "    ):\n",
    "        if use_albumentations:\n",
    "            # Albumentations Transformations\n",
    "            self.data_transform = {\n",
    "                # Implement only train\n",
    "                \"train\": A.Compose(\n",
    "                    [\n",
    "                        A.HorizontalFlip(p=0.5),\n",
    "                        A.Rotate(-10, 10),\n",
    "                        A.Resize(input_size, input_size),  # resize(input_size)\n",
    "                        # Standardization of color information\n",
    "                        A.Normalize(color_mean, color_std),\n",
    "                        ToTensorV2(),\n",
    "                    ]\n",
    "                ),\n",
    "                \"val\": A.Compose(\n",
    "                    [\n",
    "                        A.Resize(input_size, input_size),  # resize(input_size)\n",
    "                        # Standardization of color information\n",
    "                        A.Normalize(color_mean, color_std),\n",
    "                        ToTensorV2(),\n",
    "                    ]\n",
    "                ),\n",
    "            }\n",
    "        else:\n",
    "            # PyTorch Transformations\n",
    "            self.data_transform = {\n",
    "                # Implement only train\n",
    "                \"train\": transforms.Compose(\n",
    "                    [\n",
    "                        transforms.RandomHorizontalFlip(p=0.5),\n",
    "                        transforms.RandomRotation((-10, 10)),\n",
    "                        transforms.Resize(input_size),  # resize(input_size)\n",
    "                        transforms.Normalize(color_mean, color_std),\n",
    "                        transforms.ToTensor(),\n",
    "                    ]\n",
    "                ),\n",
    "                \"val\": transforms.Compose(\n",
    "                    [\n",
    "                        transforms.Resize(input_size),  # resize(input_size)\n",
    "                        transforms.Normalize(color_mean, color_std),\n",
    "                        transforms.ToTensor(),\n",
    "                    ]\n",
    "                ),\n",
    "            }\n",
    "\n",
    "    def __call__(self, phase, image):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        phase : 'train' or 'val'\n",
    "            Specifies the preprocessing mode.\n",
    "        \"\"\"\n",
    "        transformed = self.data_transform[phase](image=image)\n",
    "        return transformed[\"image\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(\n",
    "    df,\n",
    "    seed=StaticLearningParameter.SEED.value,\n",
    "    input_size=StaticLearningParameter.INPUT_SIZE.value,\n",
    "    color_mean=StaticLearningParameter.COLOR_MEAN.value,\n",
    "    color_std=StaticLearningParameter.COLOR_STD.value,\n",
    "):\n",
    "    \"\"\"Create dataset for training and validation.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed.\n",
    "            Defaults to StaticTrain.SEED.value.\n",
    "        input_size (int, optional): Input size.\n",
    "            Defaults to StaticDataTransform.INPUT_SIZE.value.\n",
    "        color_mean (tuple, optional): Color mean.\n",
    "            Defaults to StaticDataTransform.COLOR_MEAN.value.\n",
    "        color_std (tuple, optional): Color standard deviation.\n",
    "            Defaults to StaticDataTransform.COLOR_STD.value.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset, val_dataset: Dataset for training and validation.\n",
    "    \"\"\"\n",
    "    # data division\n",
    "    df_train, df_val = train_test_split(df, stratify=df[\"subject\"], random_state=seed)\n",
    "    if VERBOSE:\n",
    "        print(\"train num:\", len(df_train))\n",
    "        print(\"val num:\", len(df_val))\n",
    "\n",
    "    # dataset creation\n",
    "    train_dataset = Dataset(\n",
    "        df_train,\n",
    "        phase=\"train\",\n",
    "        transform=DataTransform(\n",
    "            input_size=input_size, color_mean=color_mean, color_std=color_std\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    val_dataset = Dataset(\n",
    "        df_val,\n",
    "        phase=\"val\",\n",
    "        transform=DataTransform(\n",
    "            input_size=input_size, color_mean=color_mean, color_std=color_std\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(\"train dataset size:\", len(train_dataset))\n",
    "        print(\"val dataset size:\", len(val_dataset))\n",
    "\n",
    "    if PLOT:\n",
    "        # Data retrieval example\n",
    "        image, label = train_dataset[0]\n",
    "        plt.imshow(image.permute(1, 2, 0))\n",
    "        plt.title(label)\n",
    "        plt.show()\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datamodule(\n",
    "    train_dataset, val_dataset, batch_size=StaticLearningParameter.BATCH_SIZE.value\n",
    "):\n",
    "    \"\"\"\n",
    "    Create dataloader for training and validation.\n",
    "\n",
    "    Args:\n",
    "        train_dataset: Dataset for training.\n",
    "        val_dataset: Dataset for validation.\n",
    "        batch_size (int, optional): Batch size.\n",
    "            Defaults to StaticDataLoader.BATCH_SIZE.value.\n",
    "\n",
    "    Returns:\n",
    "        datamodule: Dataloader for training and validation.\n",
    "    \"\"\"\n",
    "    datamodule = pl.LightningDataModule.from_datasets(\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        batch_size=batch_size if torch.cuda.is_available() else 4,\n",
    "        num_workers=int(os.cpu_count()),\n",
    "    )\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(\"data module created\")\n",
    "\n",
    "    return datamodule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitEfficientNet(LightningModule):\n",
    "    \"\"\"LightningModule for EfficientNet.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        lr=StaticLearningParameter.LR.value,\n",
    "        gamma=StaticLearningParameter.GAMMA.value,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.num_classes = len(StaticDataset.ACTIVITY_MAP.value.items())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward propagation.\"\"\"\n",
    "        out = self.model(x)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training step.\n",
    "\n",
    "        Args:\n",
    "            batch: batch data\n",
    "            batch_idx: batch index\n",
    "        \"\"\"\n",
    "        inputs, labels = batch\n",
    "        logits = self(inputs)\n",
    "        loss = F.nll_loss(logits, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        \"\"\"\n",
    "        Evaluation step.\n",
    "\n",
    "        Args:\n",
    "            batch: batch data\n",
    "            stage: stage name\n",
    "        \"\"\"\n",
    "        inputs, labels = batch\n",
    "        logits = self(inputs)\n",
    "        loss = F.nll_loss(logits, labels)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, labels)\n",
    "        f1 = f1_score(preds, labels)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "            self.log(f\"{stage}_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "            self.log(f\"{stage}_f1\", f1, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step.\n",
    "\n",
    "        Args:\n",
    "            batch: batch data\n",
    "            batch_idx: batch index\n",
    "        \"\"\"\n",
    "        self.evaluate(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Test step.\n",
    "\n",
    "        Args:\n",
    "            batch: batch data\n",
    "            batch_idx: batch index\n",
    "        \"\"\"\n",
    "        self.evaluate(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure optimizers.\"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            momentum=0.9,\n",
    "            # weight_decay=5e-4,\n",
    "        )\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=self.gamma)\n",
    "\n",
    "        # criterion = nn.CrossEntropyLoss()  # loss function\n",
    "\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(datamodule, class_names=StaticDataset.ACTIVITY_MAP.value.items()):\n",
    "    \"\"\"Train the model with Pytorch Lightning.\n",
    "\n",
    "    Args:\n",
    "        datamodule: Dataloader for training and validation.\n",
    "        class_names (list, optional): List of class names.\n",
    "\n",
    "    \"\"\"\n",
    "    # Create model\n",
    "    # NOTE: MODEL_NAME_0 = \"efficientnet_b0\"\n",
    "    # NOTE: MODEL_NAME_3 = \"efficientnet_b3\" this is used in the reference code\n",
    "    efficient_model = timm.create_model(\n",
    "        StaticLearningParameter.MODEL_NAME_0.value,\n",
    "        pretrained=True,\n",
    "        num_classes=len(class_names),\n",
    "    )\n",
    "\n",
    "    model = LitEfficientNet(efficient_model, lr=StaticLearningParameter.LR.value)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=StaticLearningParameter.EPOCHS.value,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        devices=\"auto\",\n",
    "        logger=CSVLogger(save_dir=\"logs/\"),\n",
    "        callbacks=[\n",
    "            LearningRateMonitor(logging_interval=\"step\"),\n",
    "            TQDMProgressBar(refresh_rate=10),\n",
    "        ],\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Operation check ###\n",
    "train_dataset, val_dataset = create_dataset(df)\n",
    "\n",
    "### Create DataLoader ###\n",
    "datamodule = create_datamodule(train_dataset, val_dataset)\n",
    "\n",
    "if VERBOSE:\n",
    "    image = datamodule.train_dataloader().dataset[0]\n",
    "    print(image[0].shape)\n",
    "\n",
    "### Train the model ###\n",
    "train(datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
