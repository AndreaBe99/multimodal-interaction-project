digraph "classes" {
rankdir=BT
charset="utf-8"
"src.app.gui.controller.App" [color="black", fontcolor="black", label=<{App|container<br ALIGN="LEFT"/>frames : dict<br ALIGN="LEFT"/>|show_frame(page_name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.gui.audio_frame.AudioFrame" [color="black", fontcolor="black", label=<{AudioFrame|audio_button_back<br ALIGN="LEFT"/>audio_button_start<br ALIGN="LEFT"/>audio_button_stop<br ALIGN="LEFT"/>audio_capture : NoneType<br ALIGN="LEFT"/>audio_image<br ALIGN="LEFT"/>audio_label<br ALIGN="LEFT"/>audio_loudness_label<br ALIGN="LEFT"/>audio_rcs_label<br ALIGN="LEFT"/>controller<br ALIGN="LEFT"/>|audio_go_back()<br ALIGN="LEFT"/>audio_start()<br ALIGN="LEFT"/>audio_stop()<br ALIGN="LEFT"/>record()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.recording.recorder_audio.AudioRecorder" [color="black", fontcolor="black", label=<{AudioRecorder|audio<br ALIGN="LEFT"/>audio_filename : str<br ALIGN="LEFT"/>audio_frames : list<br ALIGN="LEFT"/>channels : int<br ALIGN="LEFT"/>device_index : int<br ALIGN="LEFT"/>format<br ALIGN="LEFT"/>frames_per_buffer : int<br ALIGN="LEFT"/>open : bool<br ALIGN="LEFT"/>path : str<br ALIGN="LEFT"/>rate : int<br ALIGN="LEFT"/>stream<br ALIGN="LEFT"/>|record(): None<br ALIGN="LEFT"/>start(): None<br ALIGN="LEFT"/>stop(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.gui.av_frame.AudioVideoFrame" [color="black", fontcolor="black", label=<{AudioVideoFrame|audio_capture : NoneType<br ALIGN="LEFT"/>audio_loudness_label<br ALIGN="LEFT"/>audio_rcs_label<br ALIGN="LEFT"/>controller<br ALIGN="LEFT"/>icon<br ALIGN="LEFT"/>parent<br ALIGN="LEFT"/>video_button<br ALIGN="LEFT"/>video_button_start<br ALIGN="LEFT"/>video_button_stop<br ALIGN="LEFT"/>video_capture : NoneType<br ALIGN="LEFT"/>video_label<br ALIGN="LEFT"/>|change_frame_color(i)<br ALIGN="LEFT"/>record_audio()<br ALIGN="LEFT"/>update_video()<br ALIGN="LEFT"/>video_go_back()<br ALIGN="LEFT"/>video_start()<br ALIGN="LEFT"/>video_stop()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.utils.config.Colors" [color="black", fontcolor="black", label=<{Colors|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"src.app.utils.tts.ComplexTextToSpeech" [color="black", fontcolor="black", label=<{ComplexTextToSpeech|alarm_dict : dict<br ALIGN="LEFT"/>languages<br ALIGN="LEFT"/>model_name<br ALIGN="LEFT"/>path : str<br ALIGN="LEFT"/>speakers<br ALIGN="LEFT"/>tts<br ALIGN="LEFT"/>|create_file()<br ALIGN="LEFT"/>speak(alarm)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.train.dataset.DataTransform" [color="black", fontcolor="black", label=<{DataTransform|data_transform : dict<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"src.train.dataset.Dataset" [color="black", fontcolor="black", label=<{Dataset|df<br ALIGN="LEFT"/>phase<br ALIGN="LEFT"/>transform<br ALIGN="LEFT"/>|pull_item(index)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.detection.detector.Detector" [color="black", fontcolor="black", label=<{Detector|distracted<br ALIGN="LEFT"/>drowsiness<br ALIGN="LEFT"/>height : int<br ALIGN="LEFT"/>looking_away<br ALIGN="LEFT"/>loudness<br ALIGN="LEFT"/>rec : str<br ALIGN="LEFT"/>tts<br ALIGN="LEFT"/>txt_origin_alarm : tuple<br ALIGN="LEFT"/>txt_origin_drowsy : tuple<br ALIGN="LEFT"/>txt_origin_ear : tuple<br ALIGN="LEFT"/>txt_origin_gaze : tuple<br ALIGN="LEFT"/>txt_origin_gaze_time : tuple<br ALIGN="LEFT"/>width : int<br ALIGN="LEFT"/>|detect(frame: np.array, landmarks: np.array, audio_data: np.array): np.ndarray<br ALIGN="LEFT"/>plot_text_on_frame(frame: np.array, state_distraction: str, state_drownsiness: typing.Dict[str, typing.Any], state_looking_away: typing.Dict[str, typing.Any], font, fntScale, thickness): np.ndarray<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.detection.distracted.Distracted" [color="black", fontcolor="black", label=<{Distracted|device<br ALIGN="LEFT"/>model<br ALIGN="LEFT"/>|detect_distraction(image)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.detection.drowsiness.Drowsiness" [color="black", fontcolor="black", label=<{Drowsiness|ear<br ALIGN="LEFT"/>ear_treshold : float<br ALIGN="LEFT"/>height : int<br ALIGN="LEFT"/>state : dict<br ALIGN="LEFT"/>time_treshold : float<br ALIGN="LEFT"/>width : int<br ALIGN="LEFT"/>|detect_drowsiness(frame: np.array, landmarks): np.ndarray<br ALIGN="LEFT"/>plot_landmarks(frame: np.ndarray, eye_coordinates, color): np.ndarray<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.utils.ear.EyeAspectRatio" [color="black", fontcolor="black", label=<{EyeAspectRatio|image_h<br ALIGN="LEFT"/>image_w<br ALIGN="LEFT"/>left_eye_idxs : list<br ALIGN="LEFT"/>right_eye_idxs : list<br ALIGN="LEFT"/>|calculate_avg_ear(landmarks): typing.Tuple[float, tuple]<br ALIGN="LEFT"/>distance(point_1, point_2): float<br ALIGN="LEFT"/>get_ear(refer_idxs, landmarks): typing.Tuple[float, list]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.utils.face_mesh.FaceMesh" [color="black", fontcolor="black", label=<{FaceMesh|facemesh_model : FaceMesh<br ALIGN="LEFT"/>mp_drawing<br ALIGN="LEFT"/>mp_drawing_styles<br ALIGN="LEFT"/>mp_face_mesh<br ALIGN="LEFT"/>|compute_face_landmarks(frame: np.ndarray): np.ndarray<br ALIGN="LEFT"/>plot_face_mesh(frame: np.ndarray, face_landmarks: np.ndarray): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.utils.gaze.Gaze" [color="black", fontcolor="black", label=<{Gaze|camera_matrix : NoneType, ndarray<br ALIGN="LEFT"/>dist_coeffs : ndarray<br ALIGN="LEFT"/>face_coordinates_2D : dict<br ALIGN="LEFT"/>face_coordinates_3D : dict<br ALIGN="LEFT"/>frame_height : NoneType<br ALIGN="LEFT"/>frame_width : NoneType<br ALIGN="LEFT"/>left_eye_idxs : list<br ALIGN="LEFT"/>relative<br ALIGN="LEFT"/>relativeT<br ALIGN="LEFT"/>right_eye_idxs : list<br ALIGN="LEFT"/>rotation_vector : NoneType<br ALIGN="LEFT"/>transformation : NoneType<br ALIGN="LEFT"/>translation_vector : NoneType<br ALIGN="LEFT"/>|compute_eye_six_points(landmarks, eye_landmarks: list): list<br ALIGN="LEFT"/>compute_gaze(frame: np.ndarray, points: np.ndarray): float<br ALIGN="LEFT"/>compute_gaze_score(landmarks: np.ndarray, eye_landmarks: list, pupil_center: np.ndarray): tuple<br ALIGN="LEFT"/>correct_gaze(pupil: np.ndarray, eye_pupil2D: np.ndarray, head_pose: np.ndarray): np.ndarray<br ALIGN="LEFT"/>get_camera_matrix(frame: np.ndarray): np.ndarray<br ALIGN="LEFT"/>get_gaze_3d(pupil: np.ndarray, eye_ball_center: np.ndarray): np.ndarray<br ALIGN="LEFT"/>get_relative(frame: np.ndarray, points, function): np.ndarray<br ALIGN="LEFT"/>plot_gaze(frame: np.ndarray, pupil: np.ndarray, gaze: np.ndarray, roi_box, roi_center): None<br ALIGN="LEFT"/>project_points(coords): np.ndarray<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.train.model.LitEfficientNet" [color="black", fontcolor="black", label=<{LitEfficientNet|gamma : float<br ALIGN="LEFT"/>lr : float<br ALIGN="LEFT"/>model<br ALIGN="LEFT"/>num_classes<br ALIGN="LEFT"/>|configure_optimizers()<br ALIGN="LEFT"/>evaluate(batch, stage)<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>test_step(batch, batch_idx)<br ALIGN="LEFT"/>training_step(batch, batch_idx)<br ALIGN="LEFT"/>validation_step(batch, batch_idx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.detection.looking_away.LookingAway" [color="black", fontcolor="black", label=<{LookingAway|delta_time_frame<br ALIGN="LEFT"/>fps<br ALIGN="LEFT"/>gaze<br ALIGN="LEFT"/>gaze_act_tresh<br ALIGN="LEFT"/>gaze_counter : int<br ALIGN="LEFT"/>gaze_treshold : float<br ALIGN="LEFT"/>state : dict<br ALIGN="LEFT"/>time_treshold : int<br ALIGN="LEFT"/>|detect_looking_away(frame: np.array, landmarks): np.ndarray<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.detection.loudness.Loudness" [color="black", fontcolor="black", label=<{Loudness|normalization : int<br ALIGN="LEFT"/>width : int<br ALIGN="LEFT"/>|compute_loudness(data): float<br ALIGN="LEFT"/>display_loudness(rms): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.gui.main_frame.MainFrame" [color="black", fontcolor="black", label=<{MainFrame|button<br ALIGN="LEFT"/>button1<br ALIGN="LEFT"/>button2<br ALIGN="LEFT"/>controller<br ALIGN="LEFT"/>icon<br ALIGN="LEFT"/>image<br ALIGN="LEFT"/>label2<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"src.app.utils.config.Path" [color="black", fontcolor="black", label=<{Path|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"src.app.recording.recorder.Recorder" [color="black", fontcolor="black", label=<{Recorder|audio_args<br ALIGN="LEFT"/>audio_filename<br ALIGN="LEFT"/>audio_thread : NoneType<br ALIGN="LEFT"/>path_audio : str<br ALIGN="LEFT"/>path_video : str<br ALIGN="LEFT"/>video_args<br ALIGN="LEFT"/>video_filename<br ALIGN="LEFT"/>video_thread : NoneType<br ALIGN="LEFT"/>|file_manager(filename): None<br ALIGN="LEFT"/>start_AVrecording(): None<br ALIGN="LEFT"/>start_audio_recording(): None<br ALIGN="LEFT"/>start_video_recording(): None<br ALIGN="LEFT"/>stop_AVrecording(filename): None<br ALIGN="LEFT"/>stop_audio_recording(): None<br ALIGN="LEFT"/>stop_video_recording(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.utils.tts.SimpleTextToSpeech" [color="black", fontcolor="black", label=<{SimpleTextToSpeech|engine<br ALIGN="LEFT"/>voices<br ALIGN="LEFT"/>|speak(text)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.train.config.StaticDataset" [color="black", fontcolor="black", label=<{StaticDataset|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"src.train.config.StaticLearningParameter" [color="black", fontcolor="black", label=<{StaticLearningParameter|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"src.app.gui.video_frame.VideoFrame" [color="black", fontcolor="black", label=<{VideoFrame|controller<br ALIGN="LEFT"/>icon<br ALIGN="LEFT"/>video_button<br ALIGN="LEFT"/>video_button_start<br ALIGN="LEFT"/>video_button_stop<br ALIGN="LEFT"/>video_capture : NoneType<br ALIGN="LEFT"/>video_label<br ALIGN="LEFT"/>|change_frame_color(i)<br ALIGN="LEFT"/>update_video()<br ALIGN="LEFT"/>video_go_back()<br ALIGN="LEFT"/>video_start()<br ALIGN="LEFT"/>video_stop()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.recording.recorder_video.VideoRecorder" [color="black", fontcolor="black", label=<{VideoRecorder|blink_alarm : bool<br ALIGN="LEFT"/>detector<br ALIGN="LEFT"/>device_index : int<br ALIGN="LEFT"/>face_mesh<br ALIGN="LEFT"/>fourcc : str<br ALIGN="LEFT"/>fps : int<br ALIGN="LEFT"/>frameSize : tuple<br ALIGN="LEFT"/>frame_counts : int<br ALIGN="LEFT"/>height<br ALIGN="LEFT"/>open : bool<br ALIGN="LEFT"/>path : str<br ALIGN="LEFT"/>start_time<br ALIGN="LEFT"/>video_cap<br ALIGN="LEFT"/>video_filename : str<br ALIGN="LEFT"/>video_out<br ALIGN="LEFT"/>video_writer<br ALIGN="LEFT"/>width<br ALIGN="LEFT"/>|get_frame()<br ALIGN="LEFT"/>record(): None<br ALIGN="LEFT"/>start(): None<br ALIGN="LEFT"/>stop(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"src.app.detection.detector.Detector" -> "src.app.recording.recorder_video.VideoRecorder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="detector", style="solid"];
"src.app.detection.distracted.Distracted" -> "src.app.detection.detector.Detector" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="distracted", style="solid"];
"src.app.detection.drowsiness.Drowsiness" -> "src.app.detection.detector.Detector" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="drowsiness", style="solid"];
"src.app.detection.looking_away.LookingAway" -> "src.app.detection.detector.Detector" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="looking_away", style="solid"];
"src.app.detection.loudness.Loudness" -> "src.app.detection.detector.Detector" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="loudness", style="solid"];
"src.app.recording.recorder_audio.AudioRecorder" -> "src.app.gui.audio_frame.AudioFrame" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="audio_capture", style="solid"];
"src.app.recording.recorder_audio.AudioRecorder" -> "src.app.gui.av_frame.AudioVideoFrame" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="audio_capture", style="solid"];
"src.app.recording.recorder_audio.AudioRecorder" -> "src.app.recording.recorder.Recorder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="audio_thread", style="solid"];
"src.app.recording.recorder_audio.AudioRecorder" -> "src.app.recording.recorder.Recorder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="audio_thread", style="solid"];
"src.app.recording.recorder_video.VideoRecorder" -> "src.app.gui.av_frame.AudioVideoFrame" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="video_capture", style="solid"];
"src.app.recording.recorder_video.VideoRecorder" -> "src.app.gui.video_frame.VideoFrame" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="video_capture", style="solid"];
"src.app.recording.recorder_video.VideoRecorder" -> "src.app.recording.recorder.Recorder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="video_thread", style="solid"];
"src.app.recording.recorder_video.VideoRecorder" -> "src.app.recording.recorder.Recorder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="video_thread", style="solid"];
"src.app.utils.ear.EyeAspectRatio" -> "src.app.detection.drowsiness.Drowsiness" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ear", style="solid"];
"src.app.utils.face_mesh.FaceMesh" -> "src.app.recording.recorder_video.VideoRecorder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="face_mesh", style="solid"];
"src.app.utils.gaze.Gaze" -> "src.app.detection.looking_away.LookingAway" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="gaze", style="solid"];
"src.app.utils.tts.SimpleTextToSpeech" -> "src.app.detection.detector.Detector" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tts", style="solid"];
}
